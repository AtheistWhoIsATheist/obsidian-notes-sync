---
title: "2025-11-27 Daily_Note"
tags:
---
# What did I think about on Thu, 2025-11-27?

## Memberry- Prompt Engineering Best Practices

Below is a full, self-contained guide to expert-level prompt engineering, with:
	•	Clear instructions on how to use it
	•	A progressive, layered structure
	•	Explicit guidance on length, format, and segmentation
	•	Concrete examples and a ready-made meta-prompt you can reuse

⸻

#### 0. How to Use This Document

You can use this in three main ways:
	1.	As a learning guide
	•	Read from start to finish to internalize principles of expert prompt design.
	•	Each section builds on the previous, from basics to systems-level practice.
	2.	As a design checklist
	•	When crafting a prompt, skim the headings and ask:
	•	Did I define the objective and audience?
	•	Did I specify output format and length?
	•	Did I control assumptions and “I don’t know”?
	•	Use the final checklists to quickly stress-test a prompt.
	3.	As a meta-prompt for the model itself
	•	Copy the “Meta-Prompt to Apply These Best Practices” section into your prompt.
	•	Ask the model to rewrite or design a task-specific prompt following this guide.

Whenever you see {{LIKE_THIS}}, that’s a placeholder for content you fill in.

⸻

#### 1. Core Principles (High-Level Rules You Never Skip)

These are the non-negotiable ideas behind everything else.
	1.	Clarity over cleverness
	•	The model is extremely good at pattern-matching, but not at guessing fuzzy intent.
	•	Clear, explicit instructions outperform poetic or “vibe-based” prompts.
	2.	Specificity over generality
	•	“Explain quantum computing for a 14-year-old in 300 words, using at least one analogy”
is superior to “Explain quantum computing simply.”
	3.	Structure over prose
	•	Treat a prompt like a specification, not like an email.
	•	Headings, numbered lists, schemas, and examples make behavior far more reliable.
	4.	Iteration over one-shot
	•	Good prompts come from cycles of: design → test → observe failure → refine.
	•	A mediocre prompt iterated 5 times is usually better than a “perfect” first draft.
	5.	Control over output
	•	You decide: length, tone, sections, format, style, assumptions, safety constraints.
	•	If you don’t specify it, the model will improvise it.

Keep these five in mind; everything that follows is an elaboration of them.

⸻

#### 2. Problem Definition & Intent (What You Want, Why, and for Whom)

2.1 Explicit Objective

Best Practice: Define exactly what the model must produce.
	•	Weak: “Help with my research on AI ethics.”
	•	Strong:
“Produce a 700–900 word literature review on AI ethics in healthcare, focusing on informed consent and algorithmic bias, for a graduate seminar. Include 3–5 key authors and competing positions.”

Implementation Pattern:

PRIMARY OBJECTIVE:
- {{Describe the one main outcome you need in 1–2 sentences.}}

SECONDARY OBJECTIVES (optional):
- {{Secondary objective #1}}
- {{Secondary objective #2}}
If trade-offs are necessary, prioritize the PRIMARY OBJECTIVE over secondary ones.


⸻

#### 2.2 Audience & Use-Case

Best Practice: State clearly who will read the result and how it will be used.
	•	Audience: “non-technical executives”, “senior backend engineers”, “undergraduate philosophy students”, etc.
	•	Use-case: “slides in a pitch deck”, “draft email”, “technical RFC section”, “lecture notes”.

Example:

AUDIENCE:
- Non-technical executives with limited time.

USE CASE:
- The answer will be turned into 5 slides for a board presentation.

IMPLICATION:
- Prioritize clarity, concision, and business impact; avoid low-level technical detail.

The model can only adapt style and content if it knows these constraints.

⸻

#### 2.3 Scope and Boundaries

Best Practice: Define not only what to talk about, but what to ignore.

SCOPE (INCLUDE):
- {{Include topics A, B, C}}

OUT OF SCOPE (EXCLUDE):
- {{Explicitly exclude topics D, E}}

If a topic lies near the boundary, briefly note it and explicitly mark it as out of scope.

This prevents digressions and generic “everything plus the kitchen sink” answers.

⸻

#### 3. Instruction Architecture (How You Tell the Model What to Do)

3.1 Segmented Instruction Layout

Use a simple, repeated structure in your prompts:
	1.	ROLE
	2.	CONTEXT
	3.	OBJECTIVE
	4.	TASK BREAKDOWN
	5.	OUTPUT FORMAT
	6.	CONSTRAINTS & STYLE
	7.	EXAMPLES (optional)

This structure alone removes a huge amount of ambiguity.

⸻

3.2 ROLE Specification

Best Practice: Assign a role only when it changes behavior meaningfully.
	•	Good: “You are a senior DevOps engineer experienced in Kubernetes and observability.”
	•	Bad: “You are a god-tier omniscient wizard of everything.”

Template:

ROLE:
You are {{ROLE_DESCRIPTION}}.
Your expertise includes {{KEY_DOMAINS}}.
You do NOT claim experiential knowledge or personal feelings; focus on domain knowledge and reasoning.


⸻

3.3 Task Breakdown (Stepwise Spec)

Decompose what you want into explicit steps.

Example Pattern:

TASK:
Perform the task in **four stages**:

1. Understanding:
   - Restate the user’s problem in your own words.
   - Identify key constraints and goals.

2. Analysis:
   - List the main factors, trade-offs, or components.
   - Explore at least {{N}} distinct possible approaches.

3. Decision / Synthesis:
   - Choose the best approach (or combination).
   - Justify the choice relative to goals and constraints.

4. Final Output:
   - Construct the final deliverable in the format specified in OUTPUT FORMAT.

This is both human-readable and an implicit execution plan for the model.

⸻

#### 4. Input Handling & Delimitation (Making the Model See What You See)

4.1 Clear Delimiters for Raw Data

When you include long text, code, or notes, isolate them clearly.

===SOURCE START===
{{Your text, code, transcript, etc.}}
===SOURCE END===

When there are multiple sources:

===DOC A===
...
===DOC B===
...

Then refer to them as “DOC A” and “DOC B” in your instructions.

⸻

4.2 Minimal but Critical Metadata

Provide the minimum structural context that changes interpretation:
	•	For code: language, runtime, frameworks, environment.
	•	For documents: date, genre (legal, academic, blog), audience.
	•	For policies: jurisdiction, time period, relevant domain.

Example:

METADATA:
- Language: TypeScript
- Runtime: Node 18
- Framework: NestJS
- Database: Postgres
- Deployment: Kubernetes, autoscaling enabled


⸻

4.3 Normalization Pass (Optional but Powerful)

For messy input (typos, transcripts, braindumps), add an explicit normalization step.

STEP 1:
- Rewrite the following text with correct spelling and punctuation, preserving meaning.

STEP 2:
- Based ONLY on the normalized text, perform {{TASK}}.

This improves downstream reasoning, especially in multi-step workflows.

⸻

#### 5. Output Format, Length, and Segmentation Control

5.1 Structural Skeleton

Define the top-level structure of the response:

OUTPUT FORMAT:
Organize the final answer into the following sections:

1. {{SECTION_TITLE_1}}
2. {{SECTION_TITLE_2}}
3. {{SECTION_TITLE_3}}

Each section should be clearly labeled with a markdown heading.

This guarantees readability and consistency across uses.

⸻

5.2 Length Constraints

Be explicit and numeric.
	•	Word-based: “300–400 words total”; “50–80 words per section”.
	•	Bullet-based: “4–6 bullet points”; “max 15 bullets overall.”
	•	Paragraph-based: “2–3 paragraphs per section, each ≤ 4 sentences.”

Template:

LENGTH:
- Overall: {{MIN}}–{{MAX}} words.
- Section 1: {{MIN1}}–{{MAX1}} words.
- Section 2: {{MIN2}}–{{MAX2}} words.
- Bullet lists: max {{N_BULLETS}} bullets, each ≤ {{N_WORDS}} words.

Without this, the model tends to be either too verbose or too short.

⸻

5.3 Machine-Readable Formats (JSON, YAML, CSV)

When you want to parse or pipe the output:
	1.	Provide a schema.
	2.	Demand no extra text.
	3.	Forbid markdown fences unless you explicitly want them.

Example:

OUTPUT FORMAT (STRICT JSON):
Return ONLY valid JSON matching this schema:

{
  "title": string,
  "audience": "expert" | "intermediate" | "novice",
  "key_points": string[],        // 3–7 elements
  "risks": string[],             // 0–5 elements
  "recommended_next_actions": string[] // 1–5 elements
}

- Do NOT add comments, explanations, or markdown.
- Do NOT include extra keys.


⸻

5.4 Segmenting for Readability (Human-Facing Outputs)

For human readers:
	•	Use headings and subheadings.
	•	Short paragraphs (2–4 sentences).
	•	Limited bullets and numbered lists for key items.
	•	Avoid large blocks of unbroken text.

You can enforce this:

READABILITY RULES:
- Use markdown headings for main sections.
- Keep paragraphs ≤ 4 sentences.
- Use bullet points for lists; avoid nested bullets beyond 2 levels.
- Avoid long, unstructured walls of text.


⸻

#### 6. Reasoning, Assumptions, and “I Don’t Know”

6.1 Assumption Surfacing

Have the model list assumptions explicitly.

ASSUMPTIONS:
Before giving the final answer, list the key assumptions you are making, labeled clearly as “Assumptions”.

If strong assumptions are required due to missing info, call this out explicitly.

This makes hidden guesses visible and correctable.

⸻

6.2 Options Before Commitment

Encourage exploration of alternatives:

ALTERNATIVE APPROACHES:
- Propose {{N}} distinct approaches.
- For each, describe:
  - The core idea (2–3 sentences)
  - Advantages (2–4 bullet points)
  - Disadvantages / risks (2–4 bullet points)

Then, pick one approach as your recommended choice and explain why.


⸻

6.3 Legitimizing Uncertainty

Make “I don’t know” an allowed outcome.

UNCERTAINTY:
- If you lack information to answer precisely, say so directly.
- Use phrases like “Unknown given provided information” or “This depends on X, which is not specified.”
- Do NOT fabricate facts or sources to appear more certain.


⸻

6.4 Self-Review Step

Ask the model to self-audit before finalizing:

SELF-REVIEW:
Before presenting the final answer, silently check for:

- Compliance with OUTPUT FORMAT.
- Respect for length and style constraints.
- Contradictions or obvious logical errors.

Then output only the corrected final answer, not the review process.


⸻

#### 7. Safety, Epistemic Hygiene, and Ethical Boundaries

7.1 Restricted Domains

Specify domains where guidance must be limited or redirected:

SAFETY:
- Do NOT provide:
  - Medical diagnoses or treatment plans.
  - Legal representation or definitive legal advice.
  - Instructions for illegal, harmful, or unsafe activities.

If asked, respond by:
- Explaining why you cannot comply.
- Suggesting safer, high-level alternatives or questions.


⸻

7.2 Fact vs. Speculation Labels

Separate what is known from what is guessed:

FACT VS HYPOTHESIS:
- Mark high-confidence, well-established claims with [FACT].
- Mark conjectural or interpretive content with [HYPOTHESIS].

This is especially useful for research and forecasting tasks.

⸻

7.3 Confidence Levels

Add subjective confidence to claims:

For each key claim or recommendation, append a confidence label:
- (Confidence: high) = widely accepted / strongly supported.
- (Confidence: medium) = plausible but not guaranteed.
- (Confidence: low) = speculative or dependent on unstated variables.


⸻

#### 8. Iteration, Debugging, and Evaluation

8.1 Treat Prompts Like Code
	•	Version them (prompt_v1.0, v1.1, etc.).
	•	Document changes and observed effects.
	•	Keep them somewhere persistent (vault, repo, notes).

⸻

8.2 Classifying Failures

When an output is wrong or unsatisfying, classify:
	•	Misunderstood objective
	•	Ignored constraint
	•	Wrong audience tone
	•	Hallucinated details
	•	Poor structure or format

Then adjust the prompt at the level of the failure. Example:
	•	If format is wrong → strengthen OUTPUT FORMAT spec.
	•	If hallucination → strengthen uncertainty instructions and safety rules.
	•	If tone is off → revise TONE and micro-style rules.

⸻

8.3 Test Suites of Inputs

Maintain a small set of test prompts:
	•	Easy / typical case
	•	Realistic, messy case
	•	Edge case / near failure
	•	Adversarial / pathological case

Re-run these whenever you change your prompt. This gives you a basic “unit test” suite.

⸻

8.4 A/B Prompt Testing

For serious workflows:
	1.	Create two prompt variants (A and B).
	2.	Run them on the same test inputs.
	3.	Compare outputs based on your success criteria.

Keep whichever performs better, or merge the best parts into a new C variant.

⸻

9. Style, Tone, and Rhetoric

9.1 Tone Specification

Define tone explicitly:
	•	Examples:
	•	“Formal, academic, and dispassionate.”
	•	“Direct, pragmatic, and unsentimental.”
	•	“Friendly, conversational, and encouraging.”

Template:

TONE:
- Use a {{TONE_DESCRIPTION}} tone aligned with the AUDIENCE and USE CASE.
- Avoid flattery or hype unless explicitly requested.


⸻

9.2 Micro-Style Rules

Control fine-grained style:

STYLE RULES:
- Avoid rhetorical questions.
- No exclamation marks.
- Avoid clichés and platitudes (“think outside the box”, etc.).
- Prefer concrete nouns and verbs over abstractions.
- Use active voice whenever possible.


⸻

9.3 Structural Rhetorical Patterns

For arguments and analyses, pick a pattern:
	•	Problem → Analysis → Recommendation
	•	Claim → Evidence → Counterargument → Reply
	•	Situation → Complication → Resolution

Example constraint:

STRUCTURE:
For each key issue, use:
- Claim: 1–2 sentences
- Evidence: 2–4 bullet points
- Implications: 2–3 sentences


⸻

10. Libraries, Templates, and Meta-

10.1 Reusable Templates

Maintain generic templates for:
	•	Summarization
	•	Critique
	•	Code review
	•	Research synthesis
	•	Lesson planning
	•	Philosophical analysis
	•	UX critique
	•	Bug diagnosis

Each template should encode:
	•	Role
	•	Context
	•	Objective
	•	Output format
	•	Constraints
	•	Optional *examples*